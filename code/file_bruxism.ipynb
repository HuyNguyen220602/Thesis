{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyedflib in /home/Duchuy220602/miniconda3/lib/python3.11/site-packages (0.1.37)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/Duchuy220602/miniconda3/lib/python3.11/site-packages (from pyedflib) (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyedflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "import os\n",
    "import numpy as np\n",
    "import mne \n",
    "import shutil\n",
    "from mne.datasets import eegbci\n",
    "from mne.datasets import sleep_physionet\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mne.preprocessing import (ICA, corrmap, create_ecg_epochs,\n",
    "                               create_eog_epochs)\n",
    "import torch\n",
    "import numpy as np\n",
    "import platform, os, re, multiprocessing\n",
    "import pyedflib\n",
    "import time  # Import the time module\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import platform, os, re, multiprocessing\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import time  # Import the time module\n",
    "import os\n",
    "import mne\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import mne\n",
    "import shutil\n",
    "from mne.datasets import eegbci\n",
    "from mne.datasets import sleep_physionet\n",
    "import pandas as pd\n",
    "from mne.preprocessing import (ICA, corrmap, create_ecg_epochs,\n",
    "                               create_eog_epochs)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from datetime import timedelta\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10275/3686919123.py:18: RuntimeWarning: Number of records from the header does not match the file size (perhaps the recording was not stopped before exiting). Inferring from the file size.\n",
      "  raw = mne.io.read_raw_edf(file, preload=True, verbose=0, infer_types=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<RawEDF | brux2.edf, 18 x 4009088 (31321.0 s), ~550.6 MB, data loaded>, <RawEDF | brux1.edf, 18 x 1835648 (14341.0 s), ~252.1 MB, data loaded>]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path = \"/home/Duchuy220602/thesis/physionet.org/files/capslpdb/1.0.0\"\n",
    "pattern = \"brux*.edf\"\n",
    "\n",
    "raw_list = []\n",
    "\n",
    "for file_path in glob.glob(os.path.join(path, pattern)):\n",
    "    raw_list.append(file_path)\n",
    "    \n",
    "# Define the desired sampling frequency\n",
    "desired_sfreq = 128\n",
    "\n",
    "# Read each file and append to a list of Raw objects\n",
    "raw_objects = []\n",
    "for file in raw_list:\n",
    "    raw = mne.io.read_raw_edf(file, preload=True, verbose=0, infer_types=True)\n",
    "    raw_objects.append(raw)\n",
    "\n",
    "# Resample each Raw object to the desired sampling frequency\n",
    "for raw_obj in raw_objects:\n",
    "    raw_obj.resample(desired_sfreq)\n",
    "\n",
    "print(raw_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Annotations | 1418 segments: MT (8), REM (179), S1 (130), S2 (691), S3 ...>\n",
      "<Annotations | 1511 segments: MT (3), R (207), S1 (162), S2 (482), S3 ...>\n"
     ]
    }
   ],
   "source": [
    "path_csv = \"/home/Duchuy220602/thesis/file_csv\"\n",
    "file_csv = \"brux*.csv\"\n",
    "\n",
    "csv_list = []\n",
    "\n",
    "for file_path in glob.glob(os.path.join(path_csv, file_csv)):\n",
    "    csv_list.append(file_path)\n",
    "\n",
    "for i in range(len(raw_objects)):\n",
    "    raw = raw_objects[i]\n",
    "    csv = csv_list[i]\n",
    "\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "    # Convert the 'Time [hh:mm:ss]' column to a time format\n",
    "    df['Time [hh:mm:ss]'] = pd.to_datetime(df['Time [hh:mm:ss]'], format='%H:%M:%S').dt.time\n",
    "\n",
    "    # Extract the necessary columns from your DataFrame\n",
    "    duration = df['Duration[s]']\n",
    "    description = df['Sleep Stage']\n",
    "\n",
    "    # Convert onset times to seconds\n",
    "    onset = list(range(0, len(df)))  # Replace with your actual onset times\n",
    "\n",
    "    # Create MNE Annotations\n",
    "    my_annot = mne.Annotations(onset=onset, duration=duration, description=description)\n",
    "\n",
    "    # Set annotations on the copied EEG data\n",
    "    raw.set_annotations(my_annot)\n",
    "\n",
    "    # Print the annotations\n",
    "    print(raw.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to concatenate the Raw objects into a single object\n",
    "raw = mne.concatenate_raws(raw_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Annotations | 2931 segments: BAD boundary (1), EDGE boundary (1), MT ...>\n"
     ]
    }
   ],
   "source": [
    "# Print the concatenated annotations\n",
    "print(raw.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/Duchuy220602/thesis/modify_file/brux_concatenated_raw.fif\n",
      "Closing /home/Duchuy220602/thesis/modify_file/brux_concatenated_raw.fif\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "# raw.save('/home/Duchuy220602/thesis/modify_file/brux_concatenated_raw.fif', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
