{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "import os\n",
    "import numpy as np\n",
    "import mne \n",
    "import shutil\n",
    "from mne.datasets import eegbci\n",
    "from mne.datasets import sleep_physionet\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mne.preprocessing import (ICA, corrmap, create_ecg_epochs,\n",
    "                               create_eog_epochs)\n",
    "import torch\n",
    "import numpy as np\n",
    "import platform, os, re, multiprocessing\n",
    "import pyedflib\n",
    "import time  # Import the time module\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import platform, os, re, multiprocessing\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import time  # Import the time module\n",
    "import os\n",
    "import mne\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import mne\n",
    "import shutil\n",
    "from mne.datasets import eegbci\n",
    "from mne.datasets import sleep_physionet\n",
    "import pandas as pd\n",
    "from mne.preprocessing import (ICA, corrmap, create_ecg_epochs,\n",
    "                               create_eog_epochs)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from datetime import timedelta\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco1.edf', '/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco2.edf', '/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco3.edf', '/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco4.edf', '/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco5.edf']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path = \"/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/\"\n",
    "raw_list = []\n",
    "\n",
    "for i in range(1, 30):  # Adjust the range as needed based on the number of files you have\n",
    "    pattern = f\"narco{i}.edf\"\n",
    "    file_path = os.path.join(path, pattern)\n",
    "    if os.path.exists(file_path):\n",
    "        raw_list.append(file_path)\n",
    "\n",
    "print(raw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<RawEDF | narco1.edf, 15 x 4331520 (33840.0 s), ~495.7 MB, data loaded>, <RawEDF | narco2.edf, 13 x 4412160 (34470.0 s), ~437.6 MB, data loaded>, <RawEDF | narco3.edf, 10 x 5894528 (46051.0 s), ~449.7 MB, data loaded>, <RawEDF | narco4.edf, 18 x 5030400 (39300.0 s), ~690.8 MB, data loaded>, <RawEDF | narco5.edf, 14 x 3133440 (24480.0 s), ~334.7 MB, data loaded>]\n"
     ]
    }
   ],
   "source": [
    "# Define the desired sampling frequency\n",
    "desired_sfreq = 128\n",
    "\n",
    "# Read each file and append to a list of Raw objects\n",
    "raw_objects = []\n",
    "for file in raw_list:\n",
    "    raw = mne.io.read_raw_edf(file, preload=True, verbose=0, infer_types=True)\n",
    "    raw_objects.append(raw)\n",
    "\n",
    "# Resample each Raw object to the desired sampling frequency\n",
    "for raw_obj in raw_objects:\n",
    "    raw_obj.resample(desired_sfreq)\n",
    "\n",
    "print(raw_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, raw in enumerate(raw_objects):\n",
    "#     print(f\"Plotting Raw object {i+1}...\")\n",
    "#     raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Annotations | 1320 segments: MT (4), R (402), S1 (136), S2 (388), S3 ...>\n",
      "<Annotations | 1950 segments: R (168), S1 (24), S2 (1151), S3 (199), S4 ...>\n",
      "<Annotations | 1948 segments: MT (6), R (222), S1 (172), S2 (526), S3 ...>\n",
      "<Annotations | 1517 segments: MT (7), R (239), S1 (52), S2 (537), S3 ...>\n",
      "<Annotations | 1016 segments: MT (1), R (215), S1 (29), S2 (277), S3 ...>\n"
     ]
    }
   ],
   "source": [
    "path_csv = \"/home/Duchuy220602/thesis/file_csv\"\n",
    "csv_list = []\n",
    "\n",
    "for i in range(1, 30):  # Adjust the range as needed based on the number of files you have\n",
    "    file_pattern = f\"narco{i}.csv\"\n",
    "    file_path = os.path.join(path_csv, file_pattern)\n",
    "    if os.path.exists(file_path):\n",
    "        csv_list.append(file_path)\n",
    "\n",
    "\n",
    "for i in range(len(raw_objects)):\n",
    "    raw = raw_objects[i]\n",
    "    csv = csv_list[i]\n",
    "\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "    # Convert the 'Time [hh:mm:ss]' column to a time format\n",
    "    df['Time [hh:mm:ss]'] = pd.to_datetime(df['Time [hh:mm:ss]'], format='%H:%M:%S').dt.time\n",
    "\n",
    "    # Extract the necessary columns from your DataFrame\n",
    "    duration = df['Duration[s]']\n",
    "    description = df['Sleep Stage']\n",
    "\n",
    "    # Convert onset times to seconds\n",
    "    onset = list(range(0, len(df)))  # Replace with your actual onset times\n",
    "\n",
    "    # Create MNE Annotations\n",
    "    my_annot = mne.Annotations(onset=onset, duration=duration, description=description)\n",
    "\n",
    "    # Set annotations on the copied EEG data\n",
    "    raw.set_annotations(my_annot)\n",
    "\n",
    "    # Print the annotations\n",
    "    print(raw.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current and new channel names\n",
    "current_channel_names = ['C4A1']\n",
    "new_channel_names = ['C4-A1']\n",
    "\n",
    "# Iterate over the list of Raw objects\n",
    "for i in range(len(raw_objects)):\n",
    "    raw = raw_objects[i]\n",
    "    \n",
    "    # Check if the current Raw object contains any of the channels to be renamed\n",
    "    if any(channel in raw.ch_names for channel in current_channel_names):\n",
    "        # Create a channel map that maps the old channel names to the new channel names\n",
    "        channel_map = {current_channel_names[i]: new_channel_names[i] for i in range(len(current_channel_names)) if current_channel_names[i] in raw.ch_names}\n",
    "\n",
    "        # Rename the channels in the Raw object\n",
    "        raw.rename_channels(channel_map)\n",
    "\n",
    "        # Print the new channel names\n",
    "        print(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary mapping channel names to their types\n",
    "channel_types = {\n",
    "\"Fp2-F4\": \"eeg\",\n",
    "\"F4-C4\": \"eeg\",\n",
    "\"C4-P4\": \"eeg\",\n",
    "\"P4-O2\": \"eeg\",\n",
    "\"C4-A1\": \"eeg\", \n",
    "}\n",
    "\n",
    "# Define the default type for EEG channels\n",
    "default_type = 'stim'\n",
    "\n",
    "# Apply the channel type mapping to all Raw objects\n",
    "for i in range(len(raw_objects)):\n",
    "    raw = raw_objects[i]\n",
    "    # Get the channel names that are present in both the Raw object and the channel_types dictionary\n",
    "    common_channel_names = set(raw.ch_names) & set(channel_types.keys())\n",
    "    if not common_channel_names:\n",
    "        print(f\"No common channels found between the Raw object and the channel_types dictionary. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Set channel types for selected channels\n",
    "    channel_types_dict = {channel_name: channel_types.get(channel_name, default_type) for channel_name in common_channel_names}\n",
    "    raw.set_channel_types(channel_types_dict)\n",
    "\n",
    "    # Select only the EEG channels\n",
    "    eeg_channel_names = [channel_name for channel_name in common_channel_names if channel_types_dict[channel_name] == 'eeg']\n",
    "    if eeg_channel_names:\n",
    "        raw = raw.pick(eeg_channel_names)\n",
    "    else:\n",
    "        print(f\"No EEG channels found in the Raw object. Skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw object 1 has 5 channels.\n",
      "Raw object 2 has 5 channels.\n",
      "Raw object 3 has 5 channels.\n",
      "Raw object 4 has 5 channels.\n",
      "Raw object 5 has 5 channels.\n"
     ]
    }
   ],
   "source": [
    "for i, raw in enumerate(raw_objects):\n",
    "    print(f\"Raw object {i+1} has {raw.info['nchan']} channels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw object 1 (/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco1.edf)\n",
      "Raw object 2 (/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco2.edf)\n",
      "Raw object 3 (/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco3.edf)\n",
      "Raw object 4 (/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco4.edf)\n",
      "Raw object 5 (/mnt/data_lab513/data_thesis_duchuy/physionet.org/files/capslpdb/1.0.0/narco5.edf)\n"
     ]
    }
   ],
   "source": [
    "for i, raw in enumerate(raw_objects):\n",
    "    print(f\"Raw object {i+1} ({raw.filenames[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, raw in enumerate(raw_objects):\n",
    "#     print(f\"Plotting Raw object {i+1}...\")\n",
    "#     raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to concatenate the Raw objects into a single object\n",
    "raw = mne.concatenate_raws(raw_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Annotations | 7759 segments: BAD boundary (4), EDGE boundary (4), MT ...>\n"
     ]
    }
   ],
   "source": [
    "# Print the concatenated annotations\n",
    "print(raw.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/Duchuy220602/thesis/modify_file/narco_concatenated_raw.fif\n",
      "Closing /home/Duchuy220602/thesis/modify_file/narco_concatenated_raw.fif\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "raw.save('/home/Duchuy220602/thesis/modify_file/narco_concatenated_raw.fif', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
